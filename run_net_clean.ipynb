{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from modules.util.util import importstr, run_shell_cmd, get_best_model\n",
    "from modules.util.logconf import logging\n",
    "log = logging.getLogger('nb')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a semi-automated process. The learning rate will need to be manually set based on the results of the learning rate finder on the training dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First set the folder location of the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_path = 'COVID-19-20_v2/Train'     # replace with data path here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then generate a metadata file and prepare a cache of preprocessed data. This will create a metadata/df_meta.fth file as well as a cache/ folder in the current directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_shell_cmd(log, 'prepcache.CovidPrepCacheApp', f'--data-path={train_data_path}', \n",
    "              f'--num-workers={4}', f'--batch-size={20}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use lr finder to find a good learning rate. This will run the model through a hundered batches which take a few minutes to complete on the gpu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_shell_cmd(log, 'modules.util.lr_finder.LearningRateFinder')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the value of learning rate as found by the learning rate finder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Begin training. Validation will run every 5 epochs and a copy of the model parameters will be saved under saved-models/ folder. The best model based on F1 score is saved with the prefix `.best.state`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_shell_cmd(log, 'training.CovidSegmentationTrainingApp', f'--lr={learning_rate}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_data_path = 'COVID-19-20_TestSet'    # replace with inference data path here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once again, we prepare the metadata and cache files. Note that this will overwrite the metadatafile from the train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_shell_cmd(log, 'prepcache.CovidPrepCacheApp', f'--data-path={inference_data_path}', \n",
    "              f'--num-workers={4}', f'--batch-size={20}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can specify a UID from a CT scan based on the number found in the filename.\n",
    "For example, pass in `0180_0` for `volume-covid19-A-0180_0_ct.nii.gz`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_shell_cmd(log, 'inference.CovidInferenceApp', '004', f'--data-path={inference_data_path}', \n",
    "              f'--model-path={model_path}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you wish to explicitly specify a model path, just pass in a `--model-flag=\"model path\"` flag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_path = get_best_model('saved-models', '2020-12-08_19.15.04.best.state') # params = model_folder, model_file_name\n",
    "# run_shell_cmd(log, 'inference.CovidInferenceApp', '004', f'--data-path={inference_data_path}', f'--model-path={model_path}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To run inference on all of the files, simply pass the `--run-all` flag as shown below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_shell_cmd(log, 'inference.CovidInferenceApp', f'--data-path={inference_data_path}', \n",
    "              f'--model-path={model_path}', '--run-all')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
